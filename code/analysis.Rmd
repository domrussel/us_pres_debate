---
title: "A Textual Analysis of Every Presidential Debate"
author: "Dominic Russel"
date: "10/19/2020"
output: html_document
---

```{r setup, include=FALSE}

# Change this line to true to instead include all code
knitr::opts_chunk$set(echo = FALSE)

```

## Overview



This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r results='hide',message=FALSE}
library(tidyverse)
library(magrittr)
library(lubridate)
library(tidytext)
library(ggrepel)
library(ggwordcloud)
library(grid)
library(gridExtra)
library(sentimentr)
library(cleanNLP)
library(knitr)
library(kableExtra)

dat_in <- read_csv("../output/all_debate_text.csv")

dat_main <- dat_in %>% 
  filter(speaker_clean == gop_candidate |
           speaker_clean == dem_candidate | 
           speaker_clean == other_candidate) %>% 
  mutate(party = case_when(
    speaker_clean == gop_candidate ~ "Republican Candidate",
    speaker_clean == dem_candidate ~ "Democratic Candidate",
    speaker_clean == other_candidate ~ "Other Candidate"
  )) %>% 
  mutate(speaker_clean = case_when(
    speaker_clean == "B_CLINTON" ~ "B. Clinton",
    speaker_clean == "H_CLINTON" ~ "H. Clinton",
    speaker_clean == "GHW_BUSH" ~ "G.H.W. Bush",
    speaker_clean == "GW_BUSH" ~ "G.W. Bush",
    speaker_clean == "MCCAIN" ~ "McCain",
    TRUE ~ str_to_title(speaker_clean)
  ))
```

## Including Plots

```{r results='hide',message=FALSE}
word_sentiment <- dat_main %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) %>% 
  inner_join(get_sentiments("afinn"))
```

```{r results='hide',message=FALSE}
# This is a helper function that will make the metrics over time
# plots. The idea to assist ggrepel by putting a bunch of points on
# the line comes from: https://github.com/slowkow/ggrepel/issues/110
make_over_time_plot <- function(dat, x_col, y_col, label_col, color_col, y_label,
                                y_min, y_max,
                                x_nudge_col=NULL, y_nudge_col=NULL){
  
  dem_dat <- filter(dat, party=="Democratic Candidate")
  rep_dat <- filter(dat, party=="Republican Candidate")
  
  data_text <- rbind(
    as.data.frame(do.call(cbind, approx(dem_dat[[x_col]], dem_dat[[y_col]], n = 1000))),
    as.data.frame(do.call(cbind, approx(rep_dat[[x_col]], rep_dat[[y_col]], n = 1000))))
  
  data_text[[label_col]] <- ""
  data_text[[color_col]] <- NA_character_
  colnames(data_text) <- c(x_col, y_col, label_col, color_col)
  
  
  data_text$x_nudge <- 0
  data_text$y_nudge <- 0
  
  if(!is.null(x_nudge_col)){
    dat <- dat %>% 
      rename("x_nudge"=x_nudge_col)
  }
  else{
    dat$x_nudge <- 0
  }
  
  if(!is.null(y_nudge_col)){
    dat <- dat %>% 
      rename("y_nudge"=y_nudge_col)
  }
  else{
    dat$y_nudge <- 0
  }
  
  data_text <- rbind(dat, data_text)
  
  ggplot(dat, aes_string(x=x_col, y=y_col, col=color_col, label=label_col)) +
    geom_line(size=1.25) +
    geom_point(size=3) +
    geom_text_repel(data=data_text,
                    segment.size  = 0.2,
                    box.padding = 0.75,
                    show.legend = F,
                    nudge_x = data_text$x_nudge,
                    nudge_y = data_text$y_nudge,
                    force=1) +
    xlim(1958,2022) +
    ylim(y_min,y_max) +
    theme_bw() +
    theme(legend.title = element_blank()) +
    scale_color_manual(values=c("#0015BC", "#DE0100")) +
    labs(x="Election Year", y=y_label)
}
```

```{r message=FALSE, fig.width=12, fig.height=6}
dat_p1 <- word_sentiment %>% 
  # Here, drop the VP debates and other party candidates
  filter(vp_debate == 0, party != "Other Candidate") %>% 
  group_by(election, party, speaker_clean) %>% 
  summarise(avg_word_sent = mean(value)) %>% 
  ungroup %>% 
  # Some nudge columns that will be useful when we plot
  mutate(x_nudge = case_when(
    speaker_clean == "G.H.W. Bush" & election == 1992 ~ 2,
    speaker_clean == "H. Clinton" & election == 2016 ~ 5,
    TRUE ~ 0
  )) %>% 
  mutate(y_nudge = case_when(
    speaker_clean == "B. Clinton" & election == 1992 ~ -0.1,
    TRUE ~ 0
  ))


make_over_time_plot(dat_p1, x_col="election", y_col="avg_word_sent",
                    label_col="speaker_clean", color_col="party", y_label="Average Sentiment",
                    y_min=-0.6, y_max=0.7,
                    x_nudge_col="x_nudge", y_nudge_col="y_nudge")
```

```{r message=FALSE, fig.width=8, fig.height=8}
set.seed(9)

dat_p2 <- word_sentiment %>% 
  group_by(date, party, speaker_clean) %>% 
  summarise(avg_word_sent = mean(value)) %>% 
  ungroup() %>% 
  mutate(party = factor(party, levels=c("Democratic Candidate",
                                        "Republican Candidate",
                                        "Other Candidate"))) %>% 
  group_by(speaker_clean) %>% 
  mutate(rand_int=sample.int(n())) %>% 
  ungroup %>% 
  mutate(text_label = if_else(
    date >= as.Date("2016-01-01") | rand_int == 1 | avg_word_sent < -0.3 | avg_word_sent > 0.6,
    paste(speaker_clean, date), ""))

ggplot(dat_p2, aes(x=1, y=avg_word_sent, col=party, label=text_label)) +
  geom_vline(xintercept = 1, color="gray") +
  geom_point(size=2, alpha=0.35) +
  geom_text_repel(
    size = 3,
    segment.size = 0.2,
    point.padding = 0.5,
    min.segment.length = 0,
    show.legend = F
    ) +
  theme_minimal() +
  theme(
    axis.line.x  = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x  = element_blank(),
    axis.title.x = element_blank(),
    panel.grid.major.x = element_blank(),
    legend.title = element_blank()
  ) + 
  scale_color_manual(values=c("#0015BC", "#DE0100", "gray")) +
  labs(y="Average Sentiment")
```

Why are Trump's debates rated so... AFINN just gives a sentiment score. Here Trump uses a lot of very negative words

```{r message=FALSE}
trump_word_usage <- word_sentiment%>% 
  filter(speaker_clean == "Trump") %>% 
  group_by(word, value) %>% 
  summarise(n=n()) %>% 
  ungroup %>% 
  mutate(share_of_words = round((n/sum(n)) * 100, 2)) 

kennedy_word_usage<- word_sentiment %>% 
  filter(speaker_clean == "Kennedy") %>% 
  group_by(word, value) %>% 
  summarise(n=n()) %>% 
  ungroup %>% 
  mutate(share_of_words = round((n/sum(n)) * 100, 2)) 

bind_rows(
  trump_word_usage %>% arrange(value, desc(share_of_words)) %>% head(10),
  trump_word_usage %>% arrange(value, desc(share_of_words)) %>% tail(10)) %>% 
  select(Word=word, `Sentiment Value`=value, `Share of all Positive/Negative Words (%)`= share_of_words) %>% 
  kbl(caption="Trump Word Usage") %>%
  kable_paper(full_width = F, position = "float_left") %>%
  row_spec(1:10, color = "#900C3F") %>% 
  row_spec(11:20, color = "#35AC8A")


bind_rows(
  kennedy_word_usage %>% arrange(value, desc(share_of_words)) %>% head(10),
  kennedy_word_usage %>% arrange(value, desc(share_of_words)) %>% tail(10)) %>% 
  select(Word=word, `Sentiment Value`=value, `Share of all Positive/Negative Words (%)`= share_of_words) %>% 
  kbl(caption="Kennedy Word Usage") %>% 
  kable_paper(full_width = F, position = "float_right") %>%
  row_spec(1:10, color = "#900C3F") %>% 
  row_spec(11:20, color = "#35AC8A")

```

<div style="margin-bottom:750px;">
</div>


While the first plot showed that the sentiment in Biden's 1st 2020 debate performance was generally lower than the average for past candidates, Biden individual debate performances haven't been particularly negative. Here we highlight Trump's four presidential debates and Biden's two VP debates and one presidential debate.

```{r message=FALSE, fig.width=8, fig.height=8}
set.seed(9)

dat_p3 <- dat_p2 %>% 
  mutate(text_label = if_else(
    speaker_clean %in% c("Trump", "Biden"),paste(speaker_clean, date), ""))

ggplot(dat_p3, aes(x=1, y=avg_word_sent, col=party, label=text_label)) +
  geom_vline(xintercept = 1, color="gray") +
  geom_point(size=2, alpha=0.35) +
  geom_text_repel(
    size = 3,
    segment.size = 0.2,
    point.padding = 0.5,
    min.segment.length = 0,
    show.legend = F
    ) +
  theme_minimal() +
  theme(
    axis.line.x  = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x  = element_blank(),
    axis.title.x = element_blank(),
    panel.grid.major.x = element_blank(),
    legend.title = element_blank()
  ) + 
  scale_color_manual(values=c("#0015BC", "#DE0100", "gray")) +
  labs(y="Average Sentiment")
```


Instead of words we can do something more sophisticated with full sentences using the package sentimentr.

```{r message=FALSE, fig.width=12, fig.height=6}
sentence_sent <- dat_main %>% 
  filter(vp_debate == 0, party != "Other Candidate") %>% 
  group_by(election, speaker_clean, party) %>% 
  summarise(text = paste(text, collapse=" ")) %>% 
  ungroup %>% 
  get_sentences() %$%
  sentiment_by(text, list(election, speaker_clean, party)) %>% 
  as_tibble() %>% 
  select(-word_count, -sd)

make_over_time_plot(sentence_sent, x_col="election", y_col="ave_sentiment",
                    label_col="speaker_clean", color_col="party", y_label="Average Sentence-Level Sentiment",
                    y_min=-0.02, y_max=0.14)
```


And we can also look at emotion

```{r message=FALSE, fig.width=16, fig.height=12}
sentence_emotion <- dat_main %>% 
  filter(vp_debate == 0, party != "Other Candidate") %>% 
  group_by(election, speaker_clean, party) %>% 
  summarise(text = paste(text, collapse=" ")) %>% 
  ungroup %>% 
  get_sentences() %$%
  emotion_by(text, list(election, speaker_clean, party)) %>% 
  as_tibble() %>% 
  select(-word_count, -emotion_count, -sd)


disgust <- 
  make_over_time_plot(select(filter(sentence_emotion, emotion_type=="disgust"), -emotion_type),
                    x_col="election", y_col="ave_emotion",
                    label_col="speaker_clean", color_col="party", y_label="",
                    y_min=0, y_max=0.014)
anger <- 
  make_over_time_plot(select(filter(sentence_emotion, emotion_type=="anger"), -emotion_type),
                    x_col="election", y_col="ave_emotion",
                    label_col="speaker_clean", color_col="party", y_label="",
                    y_min=0.005, y_max=0.02)

fear <- 
  make_over_time_plot(select(filter(sentence_emotion, emotion_type=="fear"), -emotion_type),
                    x_col="election", y_col="ave_emotion",
                    label_col="speaker_clean", color_col="party", y_label="",
                    y_min=0.005, y_max=0.03)

trust <- 
  make_over_time_plot(select(filter(sentence_emotion, emotion_type=="trust"), -emotion_type),
                    x_col="election", y_col="ave_emotion",
                    label_col="speaker_clean", color_col="party", y_label="",
                    y_min=0.015, y_max=0.06)


grid.arrange(
  disgust + labs(title="Disgust") +
    theme(legend.position = "none", plot.title = element_text(size=16)),
  anger + 
    labs(title = "Anger") + 
    theme(legend.position = "none", plot.title = element_text(size=16)),
  fear + 
    labs(title = "Fear") +
    theme(legend.position = "none", plot.title = element_text(size=16)),
  trust + 
    labs(title = "Trust") +
    theme(legend.position = "none", plot.title = element_text(size=16)),
  nrow = 2)

```


One more thing we can do is PCA, using the..

We do lose some interpreitability, but essentially...

In 2004, they did debates focused entirely on one set of issues. This 2004 cloud was focused entirely on foreign policy and homeland security (was also a topic discussed at the Pence-Kaine debate). 

Can't be totally unique words (must be used in 10% of debates)

```{r message=FALSE, fig.width=12, fig.height=8}
# I pre-annotated the using cleanNLP. This process takes a long time.
# See the script clean_NLP_annotate.R.

anno <- read_rds("../output/annotated_all_debates.Rds")

# Do PCA using all (non-proper) Nouns, Adjectives, and Verbs
pca <- anno$token %>%
  filter(upos %in% c("NOUN", "ADJ", "VERB")) %>%
  cnlp_utils_tfidf(min_df = 0.1, max_df = 0.9, tf_weight = "lognorm") %>%
  cnlp_utils_pca()

pca <- bind_cols(anno$document, pca) %>% 
  mutate(party=factor(party, levels=c("Democratic Candidate",
                                      "Republican Candidate",
                                      "Other Candidate")))

ggplot(pca, aes(PC1, PC2, label=paste(paste(speaker_clean, date)), color=party)) +
  geom_point(alpha = 0.35, size = 4) +
  geom_text_repel(
    size = 3,
    segment.size = 0.2,
    min.segment.length = 0,
    show.legend = F
  ) +
  scale_color_manual(values=c("#0015BC", "#DE0100", "#8A8A8A")) +
  theme_void() +
  theme(legend.title = element_blank()) +
  labs(title="Principal Components Analysis (Nouns, Adjectives, and Verbs)")
  
```

Instead we can do it only using...

Here Trump is truly in a league of his own... His supporters say he speaks in a different way...

```{r message=FALSE, fig.width=12, fig.height=8}
# I pre-annotated the using cleanNLP. This process takes a long time.
# See the script clean_NLP_annotate.R.

# Do PCA using only Adjectives and Verbs
pca2 <- anno$token %>%
  filter(upos %in% c("ADJ", "VERB")) %>%
  cnlp_utils_tfidf(min_df = 0.1, max_df = 0.9, tf_weight = "lognorm") %>%
  cnlp_utils_pca()

pca2 <- bind_cols(anno$document, pca2) %>% 
  mutate(party=factor(party, levels=c("Democratic Candidate",
                                      "Republican Candidate",
                                      "Other Candidate")))

ggplot(pca2, aes(PC1, PC2, label=paste(paste(speaker_clean, date)), color=party)) +
  geom_point(alpha = 0.35, size = 4) +
  geom_text_repel(
    size = 3,
    segment.size = 0.2,
    min.segment.length = 0,
    show.legend = F
  ) +
  scale_color_manual(values=c("#0015BC", "#DE0100", "#8A8A8A")) +
  theme_void() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust=0.5)) +
  labs(title="Principal Components Analysis (Adjectives and Verbs)")
  
```

A final look, below we present bigram word clouds...

```{r message=FALSE, fig.width=10, fig.height=4}
set.seed(17)

bigrams <- dat_main %>% 
  filter(vp_debate == 0, party != "Other Candidate") %>% 
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

bigrams_separated <- bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  filter(!is.na(word1), !is.na(word2)) %>% 
  filter(word1 != "uh", word2 != "uh")

bigram_frequencies <- bigrams_filtered %>%
  group_by(election, speaker_clean, word1, word2) %>% 
  summarise(n = n()) %>% 
  ungroup %>%
  arrange(desc(n)) %>% 
  group_by(election, speaker_clean) %>% 
  slice(1:20) %>% 
  ungroup

bigram_frequencies_w_party <- dat_main %>% 
  distinct(election, speaker_clean, party) %>% 
  right_join(bigram_frequencies, by=c("election","speaker_clean")) %>% 
  mutate(n_gram = paste(word1, word2))

dems <- filter(bigram_frequencies_w_party, party == "Democratic Candidate")
repubs <- filter(bigram_frequencies_w_party, party == "Republican Candidate")

years <- unique(bigram_frequencies_w_party$election)

for(i in 1:length(years)){
  
  year <- years[i]
  
  curr_dem <- filter(dems, election == year)
    # Sometimes the speaker says his opponent's name way more than
    # all the others (e.g. Governor Romney). This leads the cloud
    # to have a weird scaling. We can still show that the word
    # was said far more but not destroy the cloud by scaling
    # it down a bit.
  curr_dem <- curr_dem %>% arrange(desc(n))
  if(curr_dem$n[1] > 1.25 * curr_dem$n[2]){
    curr_dem$n[1] <- curr_dem$n[2] * 1.25
  }
  curr_dem_name <- curr_dem$speaker_clean[1]
  
  curr_repub <- filter(repubs, election == year)
  curr_repub <- curr_repub %>% arrange(desc(n))
  if(curr_repub$n[1] > 1.25 * curr_repub$n[2]){
    curr_repub$n[1] <- curr_repub$n[2] * 1.25
  }
  curr_repub_name <- curr_repub$speaker_clean[1]
  
  p_dem <- ggplot(curr_dem, aes(label=n_gram, size=n)) +
    geom_text_wordcloud(color="#0015BC") +
    scale_size_area(max_size = 6) +
    theme_minimal() +
    theme(plot.title = element_text(size=16,
                                    hjust=0.5,
                                    color = "Black")) +
    labs(title=curr_dem_name)
  
  p_repub <- ggplot(curr_repub, aes(label=n_gram, size=n)) +
    geom_text_wordcloud(color="#DE0100") +
    scale_size_area(max_size = 6) +
    theme_minimal() +
    theme(plot.title = element_text(size=16,
                                    hjust=0.5,
                                    color = "Black")) +
    labs(title=curr_repub_name)
  
  p_both <- grid.arrange(p_dem,
                         p_repub,
                         nrow = 1,
                         top = textGrob(str_interp("${year} Election Debates"),
                                        gp=gpar(fontsize=20)))
  
  p_both
}
```
